{"meta":{"title":"Mira","subtitle":"Mira's blog here","description":"Hi! Welcome to Mira's blog !","author":"Mira Chan","url":"http://yoursite.com"},"pages":[{"title":"About My blog","date":"2018-08-15T07:50:50.468Z","updated":"2018-08-15T07:50:50.000Z","comments":false,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"Hi,welcome to Mira’s blog!欢迎来到我的博客，近期会不定期更新一些笔记。如有错误，敬请指出，谢谢！有任何问题，欢迎与我联系^_^"},{"title":"tags","date":"2018-05-18T04:03:39.000Z","updated":"2018-05-18T04:03:39.619Z","comments":true,"path":"tags/index-1.html","permalink":"http://yoursite.com/tags/index-1.html","excerpt":"","text":""},{"title":"categories","date":"2018-05-18T04:14:08.000Z","updated":"2018-08-15T07:43:18.000Z","comments":false,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"Tags","date":"2018-05-18T04:01:50.000Z","updated":"2018-08-15T07:36:16.000Z","comments":false,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"python multiprocessing 中imap和map的不同","slug":"python-multiprocessing-中imap和map的不同","date":"2018-11-20T12:42:04.000Z","updated":"2018-11-20T15:14:13.647Z","comments":true,"path":"2018/11/20/20/","link":"","permalink":"http://yoursite.com/2018/11/20/20/","excerpt":"本篇文章讲python的multiprocessing中imap、map、imap_unordered和map_async方法之间的区别。参考链接","text":"本篇文章讲python的multiprocessing中imap、map、imap_unordered和map_async方法之间的区别。参考链接 主要有以下两个区别： 它们使用你传递给它们的可迭代的对象的方式。 它们返回结果的方式。 map通过将改可迭代的对象转换为列表（假设它不是列表），将其分解为块，并将这些块发送到池中的工作进程中。将该对象分解为块比一次直接执行一个对象要更好，特别是如果可迭代的对象很大。但是，将该对象转换为列表以便进行块化可能会产生非常高的内存成本，因为整个列表需要保存在内存中。 imap不会将您提供的可迭代对象变为列表，也不会将其分解为块（默认情况下）。它将一次遍历该对象的一个元素，并将它们分别发送到工作进程。这意味着您不会将整个对象转换为列表存在内存中（命中率降低），但这也意味着大型迭代的性能较慢，因为缺少分块。但是，可以通过传递大于默认值1的chunksize参数来减轻这种情况（命中率增加）。 另一个主要的不同，在于imap/imap_unordered，你可以在工作准备就绪后立即开始接收进程的结果，而不必等待所有进程完成工作。使用map_async，虽然也会立即返回AsyncResult，但是在完成所有对象之前，您无法实际检索该对象的结果。此时它将返回映射所执行的相同列表，没有办法得到部分结果。在这个点上来说，它和map返回的情况相同;相当于说，你要么拥有整个结果，要么没有结果。 imap和imap_unordered都会立即返回结果。使用imap，结果将在它们准备就绪时从迭代中产生，同时仍保留输入可迭代的顺序。使用imap_unordered，无论输入可迭代的顺序如何，只要它们准备好就会产生结果。 所以，使用imap/imap_unordered替代map_async主要的原因有： 您的可迭代对象足够大，将其转换为列表会导致您耗尽/使用太多内存。 您希望能够在完成所有结果之前就先处理结果。","categories":[{"name":"python3笔记","slug":"python3笔记","permalink":"http://yoursite.com/categories/python3笔记/"}],"tags":[{"name":"python3","slug":"python3","permalink":"http://yoursite.com/tags/python3/"}]},{"title":"python GIL problem","slug":"python-GIL-problem","date":"2018-10-15T14:10:11.000Z","updated":"2018-11-20T15:15:11.323Z","comments":true,"path":"2018/10/15/19/","link":"","permalink":"http://yoursite.com/2018/10/15/19/","excerpt":"本篇文章主要了解一下Python 中的GIL问题。众所周知，在使用到python的多线程时，我们都会遇到GIL这个问题，使得多线程性能陷入瓶颈。 先附上参考链接：What is the Python Global Interpreter Lock(GIL)？Python的GIL是什么鬼，多线程性能究竟如何","text":"本篇文章主要了解一下Python 中的GIL问题。众所周知，在使用到python的多线程时，我们都会遇到GIL这个问题，使得多线程性能陷入瓶颈。 先附上参考链接：What is the Python Global Interpreter Lock(GIL)？Python的GIL是什么鬼，多线程性能究竟如何 什么时候会遇到GIL问题？说到GIL，很多人会把其称之为python多线程中必然会遇到的一个问题。其实不然，这不是python本身的问题，而是我们常用的一个解析器cpython所带来的问题。 而cpython只是python的一种解析器，意味着还有许多其他的解析器是没有这样一个问题的。但cpython作为最常用的一个解析器，在一定程度上受到了广大编程爱好者的青睐。 换言之，在使用python进行多线程编程时，若使用cpython解析器必然需要遇到GIL问题。 到底什么是GIL？GIL 全称 Global Interpreter Lock（全局解释器锁）。简单来说，GIL是一个互斥锁，它只允许一个线程来控制Python解释器。 这意味着在任何时间点只有一个线程可以处于执行状态，这将可能成为CPU-bound(计算密集型)多线程代码中的性能瓶颈。 而且，即使是在多核CPU的情况下也是如此，所以GIL问题可以说是臭名昭著了。 GIL对python有什么用？ Python使用“引用计数”进行内存管理。这意味着在Python中创建的对象具有“引用计数”变量，该变量用于跟踪指向对象的引用数。当此计数达到零时，释放对象占用的内存。 问题在于，当两个线程同时更改这个值时，其需要受到保护。如果没有保护好它，可能会导致内存泄露（有些内存可能永远无法释放）；更糟糕的情况比如：当对象依然存在而内存却不正常地提前释放。这可能会导致Python程序中出现崩溃或其他错误。 通过向跨线程共享的所有数据结构添加锁，可以保持此“引用计数”变量的安全，从而不会导致以上这种现象。 给每个对象或者对象组加锁，意味着可能产生多个锁，就可能产生另一个问题——死锁问题（只可能发生在有多个锁的情况）。重复地获取和释放锁将会在另一个程度上降低性能。 GIL是解释器本身的单个锁，它增加了一条规则，即执行任何Python字节码都需要获取解释器锁。这可以防止死锁（因为只有一个锁）并且不会引入太多的性能开销。但它使任何受CPU限制的Python程序都是单线程的。 GIL虽然也被解释器用于其他语言（如Ruby），但并不是解决此问题的唯一方法。有些语言通过使用除引用计数之外的方法（例如垃圾收集）来避免GIL对线程安全内存管理的要求。 为什么选择GIL来解决问题那么，为什么这样的一个方法还在python中被使用？这个方法真的这么糟糕吗？ 事实上，GIL的设计是python变得如此受欢迎的原因之一。 在python起初被使用时，操作系统还没有线程的概念。python被设计来使用开发人员可以更快更简单地编程，所以越来越多的开发人员开始使用它。 python中有许多现有的C库扩展。为了防止不一致的更改，这些C扩展需要GIL提供的线程安全内存管理。 GIL实现简单且容易整合进python。由于只需要管理单个锁，它使得python中单线程的程序性能得到提升。 有了GIL，非线程安全的C库变得更容易集成。而这些C扩展，也成为不同社区采用python的原因之一。 综上所诉，GIL确实是一个实用的解决方法，可以解决CPython开发人员在Python初期遇到的一个难题。 GIL对python多线程编程的影响 对于CPU-bound(计算密集型) 和I/O bound(I/O密集型)两种不同类型的程序，在性能上有所不同。 -CPU密集型的程序使得CPU利用达到极致，这包括进行数学计算的程序，如矩阵乘法，搜索，图像处理等。 I/O密集型程序需要花费时间等待输入\\输出，其可以来自用户、文件、数据库、网络等。其有时必须等待大量时间，直到它们从源获得所需内容。例如，用户需要考虑在实际进程中在输入框中输入什么，或者考虑从数据库中查询什么等。 由于GIL阻止了CPU密集型线程的并发执行，几乎同样的程序，采用单线程和多线程的时间，往往多线程的时间并不会比单线程的短甚至更长。 由于在等待I/O时，GIL可以在不同线程中流转，故GIL对I/O密集型多线程程序影响并不大。 为啥GIL问题仍未被移除？ python的开发人员对此有很多怨言，但若是移除GIL，则可能会导致向后不兼容问题。 GIL显然可以被删除，开发人员和研究人员过去已经多次这样做了，但所有这些尝试都破坏了现有的C扩展，这些扩展在很大程度上依赖于GIL提供的解决方案 当然，也有很多别的方法可以替代GIL，但其中有一些会降低单线程以及多线程I/O密集型程序，还有一些难以实现。毕竟，我们不希望移除GIL后得到的新版本，比旧版本性能差吧。 为什么Python3中仍然没有将它移除？ Python3 确实有机会从头开始启动很多新的功能，并打破一些现有的C扩展。但将原有的程序更新并移植到Python3仍需要时间，这也是为啥一开始Python 3在社区中并不那么受欢迎。 如果移除GIL，Python3在单线程程序上的性能将低于Python2 ，你可以说python单线程程序的性能多亏了有GIL，所以这就是为什么Python3中仍然有GIL问题。 但，在Python3中，确实针对GIL问题，做了很大的提升： 我们前面讨论了GIL对于CPU密集型以及I/O密集型程序的影响，那么当程序既是CPU密集型又是I/O密集型程序呢？ 此时，GIL问题将会使得I/O密集型线程饿死（无法从CPU密集型线程那获得GIL）。 这是因为Python的内部机制决定了GIL在固定的连续使用时间后将会被释放，但如果此时没有程序获取GIL，那么原来那个线程将会继续运行。而在这个机制中，CPU密集型线程将会在其他线程获取GIL前重新获取GIL。 这个问题在2009年由Antoine Pitrou在Python 3.2中得到修复。他添加了一种机制，可以查看被删除的其他线程的GIL获取请求数，并且在其他线程有机会运行之前不允许当前线程重新获取GIL。 那到底如何解决GIL问题呢？如果GIL给你带了麻烦，可以尝试以下几种方法： Multi-processing vs multi-threading:最受欢迎的一个方法是使用多进程代替多线程。每一个Python程序有自己的Python解释器和存储空间，所以将不会有GIL问题。Python中有一个multiprocessing 模块 。与多线程相比，多进程在性能上有了不错的提升，但时间并没有随着进程的增加而减少相应的倍数，因为进程管理有自己的开销。进程比线程的开销更大，因此这将成为多进程程序运行的瓶颈。 选择其他Python解释器：Python有很多解释器比如最受欢迎的几种：Cpython、Jython，IronPython还有Pypy，分别是由C、Java、C#和python实现的。GIL仅存在于Cpython中。如果你的程序有这些包，你也可以尝试用这些解释器。 再等等吧：很多Python使用者享用着GIL所带来的单线程程序的性能，而多线程程序的开发者也不必担心。Python社区中有一群大佬正在致力于将GIL从CPython中移除。其中，有一种尝试被称为Gilectomy,不过其实好像最近没啥动静。 GIL一直被认为是一个神秘而困难的话题。但作为开发者，如果你正在使用Ｃ扩展，或者说你的程序是CPU密集型程序，才会被GIL影响。","categories":[{"name":"python3笔记","slug":"python3笔记","permalink":"http://yoursite.com/categories/python3笔记/"}],"tags":[{"name":"python3","slug":"python3","permalink":"http://yoursite.com/tags/python3/"}]},{"title":"RNN、LSTM、GRU、seq2seq简单理解","slug":"RNN、LSTM、GRU、seq2seq简单理解","date":"2018-08-15T07:23:00.000Z","updated":"2018-08-18T16:22:49.000Z","comments":true,"path":"2018/08/15/17/","link":"","permalink":"http://yoursite.com/2018/08/15/17/","excerpt":"附上参考链接： 完全图解RNN、RNN变体、Seq2Seq、Attention机制 Understanding LSTM Networks","text":"附上参考链接： 完全图解RNN、RNN变体、Seq2Seq、Attention机制 Understanding LSTM Networks 首先，我们需要理解一下RNN的大体概念。 简单来说，RNN(Recurrent Neural Networks循环神经网络)是一种神奇的神经网络。 显然神经网络的作用，直观上可以说是一个输入，经过了网络（可能有多个隐层），形成一个输出。但普通的神经网络隐层的节点之间是没有连接的，而RNN循环神经网络（或者叫做递归神经网络）的主要特点则是隐层节点之间的连接。 举个例子来说，通常当我们讲一句话的时候，当前的字词都是和附近的字词存在一定的联系的。而对于普通的神经网络算法而言，是无法做到这一点的。RNN则使得前后文的联系成为可能。 了解到RNN大概是个什么东西，接着让我们来看看RNN、LSTM、GRU、seq2seq这几个概念之间的区别与联系。（推荐可以简单看一下参考链接里的第一篇文章） 简单总结如下：** RNN是循环神经网络。 LSTM是对RNN的一种优化（为了解决梯度爆炸或者梯度消失的问题）。 GRU是对LSTM的一种优化（使得神经网络结构更为简单） 虽然说是优化，但在不同情况下，不同算法的效果各有优劣。说白了，不是在所有情况下，优化后的算法就是更有效的。 通过RNN我们可以轻易构造出各种循环神经网络算法变种，得到“1 vs N”、“N vs 1”、“N vs N”或者“N vs M”等情况的算法。 其中“N vs M”就是我们所说的seq2seq。 具体点说，实际上我们遇到的许多问题，输入与输出的序列都是不等长的，比如机器翻译“我爱中国”是四个字，而英文“I love China”则是三。","categories":[],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/tags/机器学习/"}]},{"title":"python3中map函数的使用","slug":"python3中map函数的使用","date":"2018-08-14T08:23:18.000Z","updated":"2018-08-14T08:34:23.000Z","comments":true,"path":"2018/08/14/16/","link":"","permalink":"http://yoursite.com/2018/08/14/16/","excerpt":"以前写的笔记，现在才整理发布出来，以备查询。Mark一下python中一个好棒的内置函数：map函数。 英文教程参考链接中文教程参考链接","text":"以前写的笔记，现在才整理发布出来，以备查询。Mark一下python中一个好棒的内置函数：map函数。 英文教程参考链接中文教程参考链接 r= map(func, seq)参数 第一个参数func 是函数的名称 第二个参数seq是一个序列（比如列表list） 返回值 Python 2.x 返回列表。 Python 3.x 返回迭代器。（这里的代码都是python3的） 作用： 根据提供的函数对制定序列做映射直白点说： map()会将func函数应用于序列seq的所有元素 简单例子 函数体 123456def fahrenheit(T): &apos;&apos;&apos;返回华氏温度&apos;&apos;&apos; return ((float(9)/5)*T + 32)def celsius(T): &apos;&apos;&apos;返回摄氏温度&apos;&apos;&apos; return (float(5)/9)*(T-32) map使用 12345temperatures = (36.5, 37, 37.5, 38, 39)F = list(map(fahrenheit, temperatures))C = list(map(celsius, F))print(F)#[97.7, 98.60000000000001, 99.5, 100.4, 102.2]print(C)#[36.5, 37.00000000000001, 37.5, 38.00000000000001, 39.0] 使用lambda匿名函数123C = [39.2, 36.5, 37.3, 38, 37.8] F = list(map(lambda x: (float(9)/5)*x + 32, C))print(F)#[102.56, 97.7, 99.14, 100.4, 100.03999999999999] 可以用于多个列表 列表的元素个数要相同12print(list(map(lambda x, y: x + y, [1, 3, 5, 7, 9], [2, 4, 6, 8, 10])))# [3, 7, 11, 15, 19] 应用因为刚接触python，所以很多内置函数，如果不是真的在打代码中遇到了，可能都记不住。之所以想mark一下map函数，是在leetcode上刷到一道题: 题目链接 简单翻译一下 字符串J，代表你拥有的宝石类型。（没有重复的宝石类型）字符串S，代表你拥有的石头。你想知道这些石头里有多少是宝石。字母区分大小写，所以“A”和“a”是不同类型的石头。 例子 输入: J = “aA”, S = “aAAbbbb”输出: 3输入: J = “z”, S = “ZZ”输出: 0 一开始我的答案是这样纸的 1234567891011class Solution: def numJewelsInStones(self, J, S): count=0 jewelsIndex=[] for _,jewels in enumerate(J): newIndex=[i for i in range(len(S)) if i not in jewelsIndex] for i in newIndex: if S[i]==jewels: count+=1 jewelsIndex.append(i) return count 后来看到大神只用了一句代码 123class Solution: def numJewelsInStones(self, J, S): return sum(map(J.count, S))","categories":[{"name":"python3笔记","slug":"python3笔记","permalink":"http://yoursite.com/categories/python3笔记/"}],"tags":[{"name":"python3","slug":"python3","permalink":"http://yoursite.com/tags/python3/"}]},{"title":"python3中*星号操作符的使用","slug":"python3中*星号操作符的使用","date":"2018-08-14T07:47:19.000Z","updated":"2018-08-14T08:22:53.000Z","comments":true,"path":"2018/08/14/15/","link":"","permalink":"http://yoursite.com/2018/08/14/15/","excerpt":"我们经常会在参数传递的时候看到有些参数的前面会有*星号.或者**双星号,两者类似地有以下两个作用： 在函数声明时使用，使得函数可接收可变参数（任意个数的参数） 在函数调用时使用，用于解压参数列表。","text":"我们经常会在参数传递的时候看到有些参数的前面会有*星号.或者**双星号,两者类似地有以下两个作用： 在函数声明时使用，使得函数可接收可变参数（任意个数的参数） 在函数调用时使用，用于解压参数列表。 具体如下： 1. 对于第一个作用: * 单星号将参数以元祖的形式导入：1234567def foo(p1,*p2): print(p1) print(p2)foo(1,2,3)# 打印结果：#1#(2,3) 而**双星号，则是将参数以字典的形式导入：1234567def bar(p1,*p2): print(p1) print(p2)bar(1,a=2,b=3)# 打印结果：#1#&#123;&apos;a&apos;:2, &apos;b&apos;:3&#125; 2. 对于第二个作用：* 单星号将元祖解压为对应参数，而**双星号，则是将字典解压为对应参数。 12345678910def foo(a,b,c): print(a,b,c)p1=(1,2,3)p2=&#123;&apos;a&apos;:1,&apos;b&apos;:2,&apos;c&apos;:3&#125;foo(*p1)foo(**p2)#运行结果：#1 2 3#1 2 3","categories":[{"name":"python3笔记","slug":"python3笔记","permalink":"http://yoursite.com/categories/python3笔记/"}],"tags":[{"name":"python3","slug":"python3","permalink":"http://yoursite.com/tags/python3/"}]},{"title":"softmax函数","slug":"softmax函数","date":"2018-07-30T14:08:34.000Z","updated":"2018-08-15T07:16:54.000Z","comments":true,"path":"2018/07/30/14/","link":"","permalink":"http://yoursite.com/2018/07/30/14/","excerpt":"在数学，尤其是概率论和相关领域中，softmax函数，或称归一化指数函数，是逻辑函数的一种推广。它能将一个含任意实数的K维向量z“压缩”到另一个K维向量$\\sigma(z)$，使得每一个元素的分布都在（0,1）之间，并且所有元素的和为1。","text":"在数学，尤其是概率论和相关领域中，softmax函数，或称归一化指数函数，是逻辑函数的一种推广。它能将一个含任意实数的K维向量z“压缩”到另一个K维向量$\\sigma(z)$，使得每一个元素的分布都在（0,1）之间，并且所有元素的和为1。该函数的形式通常按下面的式子给出：$\\sigma(z)=\\frac{s^zj}{\\sum_{k=1}^Ke^zk} for j=1,…,K.$ 由于softmax的特性，我们常常把它应用于神经网络中 用做激活函数。下面这篇文章讲解了softmax和另一个常用的激活函数sigmoid函数的区别参考链接：深度学习: Softmax 函数而这篇文章则简单对比了一下几个常用的激活函数：参考链接：常用的激活函数总结(Sigmoid函数、Tanh函数、ReLu函数、Softmax函数) 用作loss计算这篇文章简要说明了，softmax函数如何用作loss计算，以及这么用的好处：参考链接：Softmax的理解与应用","categories":[],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/tags/机器学习/"}]},{"title":"神经网络：学习","slug":"神经网络：学习","date":"2018-06-23T08:02:33.000Z","updated":"2018-08-14T08:38:32.000Z","comments":true,"path":"2018/06/23/13/","link":"","permalink":"http://yoursite.com/2018/06/23/13/","excerpt":"成本函数首先,让我们来定义一些需要使用的变量: L =网络中的层数 $s_l$ =第l层中的单元数量（不包括偏差单元） K =输出单元/类的数量","text":"成本函数首先,让我们来定义一些需要使用的变量: L =网络中的层数 $s_l$ =第l层中的单元数量（不包括偏差单元） K =输出单元/类的数量 回顾上一篇文章，我们知道神经网络中可能有很多的输出节点。我们用$ h_\\Theta(x)_k$来表示假设函数输出第k个结果。 神经网络的成本函数将会是逻辑回归中成本函数的一个推广。 回想一下正则化逻辑回归的成本函数是：$J(θ)=−\\frac{1}{m}\\sum_{i=1}^m[y^{(i)}log(h_θ(x^{(i)}))+(1−y^{(i)})log(1−h_θ(x^{(i)}))]+ \\frac{λ}{2m}\\sum_{j=1}^nθ_j^2$ 对于神经网络来说，它会稍微复杂一些：$J(θ)=−\\frac{1}{m}\\sum_{i=1}^m\\sum_{k=1}^K[y^{(i)}_klog((h_θ(x^{(i)}))_k)+(1−y^{(i)}_k)log(1−(h_θ(x^{(i)}))_k)]$$+\\frac{λ}{2m}\\sum_{l=1}^{L-1}\\sum_{i=1}^{s_l}\\sum_{j=1}^{s_{l+1}}(θ_{j,i}^{(l)})^2$ 我们添加了几个嵌套总和来表示我们的多个输出节点 在方程的第一部分，我们有一个额外的嵌套总和，它根据节点的数量循环输出。 在正则化部分，我们必须考虑多个$θ$矩阵（与之前的逻辑回归一样，我们对$θ$矩阵的每一项进行平方处理）。当前层的$θ$矩阵中的列数等于当前层中的节点数（包括偏差单元）。而行数则等于下一层中的节点数（不包括偏差单元）。 注意： 双重嵌套总和只是将输出层中每个单元计算的逻辑回归成本加起来; 和是将整个网络中所有$Θ$的平方相加。 三重嵌套总和中的i并不是指提到第i个训练例子 反向传播算法“反向传播”是神经网络中的术语，用于最小化我们的成本函数，就像我们在逻辑回归和线性回归中使用梯度下降的目的是一样的。 显然，我们的目标是：$\\min_Θ J(Θ)$也就是说，我们希望使用最优的一组参数$\\theta$，以此来最小化我们的成本函数。 让我们来看看用来计算$J(\\theta)$的偏导数方程：$\\frac{∂}{∂Θ^{(l)}_{i,j}}J(Θ)$ 在反向传播中，我们将计算每一个节点：$\\delta^{(l)}_j$=l层第j个节点的“误差” 回顾，$\\alpha^{(l)}_j$表示l层第j个激活节点。 对于最后一层，我们可以计算出误差向量：$\\delta^{(L)}=a^{(L)}-y$其中，L是总共的层数，$a^{(L)}$是最后一层的激活单元的输出向量。所以，最后一层的“误差值”仅仅是我们在最后一层的实际结果和y的正确输出的差异。 要得到最后一层之前的层的$\\delta$值，我们可以使用一个方程式，让我们从右到左移进： $\\delta^{(l)} = ((\\Theta^{(l)})^T \\delta^{(l+1)})\\ .*\\ g’(z^{(l)})$ 其中， $\\delta^{(l)}$推导过程如下$\\delta^{(l)}=\\frac{∂J(\\theta)}{∂(z^{(l)})}=\\frac{∂J(\\theta)}{∂(z^{(l+1)})}.\\frac{∂(z^{(l+1)})}{∂(a^{(l)})}.\\frac{∂(a^{(l)})}{∂(z^{(l)})}$$=\\delta^{(l+1)}.\\frac{∂(Θ^{(l)}a^{(l)})}{∂(a^{(l)})}.\\ g’(z^{(l)})$$=\\delta^{(l+1)}.\\Theta^{(l)}.\\ g’(z^{(l)})$ 故：$\\delta^{(l)} = (\\Theta^{(l)})^T \\delta^{(l+1)}) .* g’(z^{(l)})$ 其中，$g’(u)=g(u).*(1-g(u))$ 总的来说，中间节点上的反向传播可以这样表示：$\\delta^{(l)} = (\\Theta^{(l)})^T \\delta^{(l+1)}) .* a^{(l)}.*(1-a^{(l)})$ 接下来，让我们来计算权重的梯度，即求$\\frac{∂}{∂Θ^{(l)}_{i,j}}J(Θ)$ 推导过程$\\frac{∂}{∂Θ^{(l)}_{i,j}}J(Θ)=\\frac{∂J(Θ)}{∂z^{(l+1)}_{i}}.\\frac{∂∂z^{(l+1)}_{i}}{∂Θ^{(l)}_{i,j}}=\\delta^{(l+1)}_i.\\frac{∂(Θ^{(l)}a^{(l)})}{∂(Θ^{(l)})}=\\delta^{(l+1)}_i.a^{(l)}$ $=\\frac{1}{m}\\sum_{t=1}^ma^{(t)(l)}.\\delta^{(l+1)}_i$ 显然，这里我们忽略了正则化,等下我们再来处理这个问题。 现在，让我们把所有公式整合在一起： 给出训练集${(x^{(1)},y^{(1)})⋯(x^{(m)} ,y^{(m)})}$ 初始化设置$Δ_{i,j}^{(l)}:= 0 对于所有的(l,i,j)$for t=1到m 的训练样本： 设置$a^{(1)}:=x^{(t)}$ 使用正向传播算法计算每一层的$a^{(l)}$for l=2,3,…,L 利用$y^{(t)}$,计算$δ^{(L)}=a^{(L)}−y^{(t)}$ 利用公式$\\delta^{(l)} = (\\Theta^{(l)})^T \\delta^{(l+1)}) .* a^{(l)}.*(1-a^{(l)})$计算$δ^{(L−1)},δ^{(L−2)},…,δ^{(2)}$ $Δ_{i,j}^{(l)}:=Δ_{i,j}^{(l)}+a_j^{(l)}δ_i^{(l+1)}$，或者向量化形式$Δ^{(l)}:=Δ^{(l)}+δ^{(l+1)}(a^{(l)})^T$ $D_{i,j}^{(l)}:=\\frac{1}{m}(Δ_{i,j}^{(l)} +λΘ_{i,j}^{(l)})$,如果 j≠0 $D_{i,j}^{(l)}:=\\frac{1}{m}Δ_{i,j}^{(l)}$,如果 j=0 总体整理一下神经网络模型首先，选择一个网络架构，选择神经网络的布局，包括每层中单元数以及总的层数。 输入单元的数量 = $x^{(i)}$维数 输出单元的数量 = 输出的类别数 每一层中隐式单元的个数 = 通常情况下越多越好（当然也需要平衡随着单元数增加而产生的计算量） 默认：一个隐层。如果多于一个隐层，那么内一个隐层的单元数是相同的。 神经网络训练流程 随机初始化权重（切不可全都为0） 实现前向传播得到$h_\\theta(x^{(i)})$ 实现成本函数 实现反向传播计算偏导数$\\frac{∂J(Θ)}{∂Θ^{(l)}_{i,j}}$ 使用梯度检测确认4中的反向传播算法是否有效，若有效则禁用此检测。（梯度检测十分耗时） 使用梯度下降或者内置优化函数来调整$\\theta$的权重，以最小化成本函数。","categories":[{"name":"Coursera Ng 笔记","slug":"Coursera-Ng-笔记","permalink":"http://yoursite.com/categories/Coursera-Ng-笔记/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/tags/机器学习/"}]},{"title":"初识神经网络","slug":"初识神经网络","date":"2018-06-13T08:45:52.000Z","updated":"2018-08-14T08:37:15.000Z","comments":true,"path":"2018/06/13/12/","link":"","permalink":"http://yoursite.com/2018/06/13/12/","excerpt":"非线性假设函数将线性回归应用在一批复杂且有很多特征的数据集是非常不明智的。","text":"非线性假设函数将线性回归应用在一批复杂且有很多特征的数据集是非常不明智的。假设你想用三个特征来组合产生所有二次项，并创建一个假设函数：$g(θ_0+θ_1x^2_1+θ_2x_1x_2+θ_3x_1x_3+θ_4x^2_2+θ_5x_2x_3+θ_6x^2_3)$可以看到，这里有6个特征，可以通过组合公式：$\\frac{n+r-1}{r!(n-1)!}$ ，来计算能产生多少个多项式组合。 比如100个特征，则可以产生$\\frac{100+2-1}{2!(n100-1)!}=5050$个二次项特征。如果想将特征组合成二次项，我们可以粗略地用$O(n^2/2)$来表示新特征数的增长情况。如果想组合成立方式的话，特征数则约为$O(n^3)$。这个增长比例是十分夸张的，所以随着特征数的增加，二次项和三次项的特征增加得十分迅速，此时若再使用线性回归是十分不切实际的。 举个例子：假设我们有一些50*50像素的黑白照片，我们的目标是分类出哪些照片是车。此时我们的特征数n=2500，如果我们比较每一个像素点。现在，如果我们需要构造一个二次项假设函数，根据前文，我们知道增长比例约为O(n^2/2)。所以，我们总共有$2500^2/2=3125000$个特征，可想而知，此时使用线性回归是十分不切实际的。 当我们遇到了很多特征的复杂函数时，神经网络提供了另一种机器学习的方法。 神经元和大脑神经网络主要是通过模仿我们的大脑是如何工作的。由于计算机硬件的进步，神经网络近期有了一次重大的复兴。（早年神经网络的提出，由于计算机硬件的限制，无法得以发展。） 有证据表明，大脑对所有不同的功能只使用一种“学习算法”。科学家们曾经试图切断耳道和听觉皮层之间的连接，并将听觉皮层重新连接到光学神经上，发现听觉皮层慢慢地学会了看。 这个原理被称为“神经可塑性”，并有许多例子和实验证据。 模型表示 I让我们来看看如何使用神经网络来表示一个假设函数。 **简单地说，神经元可以看做是一个计算单位，它们将（来自树突的）输入作为电输入，（经过轴突）将其引导到输出。 在我们的模型当中，树突的输入相当于我们的输入特征$x_1…x_n$,而输出则是我们的假设函数：** 在这个模型中，我们的$X_0$输入节点也被成为“偏向单元”，其总是为1。在神经网络中，我们使用同样的逻辑函数用于分类：$\\frac{1}{1+e^{Θ^Tx}}$。有时，我们也把它称为sigmoid（逻辑）激活函数。 其中，在神经网络模型中，$Θ$参数经常被称为”权重”。一个简单的模型表示如下：$\\begin{bmatrix}x_0 \\\\ x_1\\\\ x_2\\end{bmatrix}→\\begin{bmatrix}\\end{bmatrix}→h_Θ(x)$在上面这个模型中，我们的输入节点（层1）被传入另一个节点（层2)，并作为假设函数输出。第一层也被成为“输入层”，最后一层被称为“输出层”，输出层会给出通过假设函数输出的最终值。 我们可以在输入层和输出层之间加入中间层节点，称为“隐层”。我们给这些中间层（或者叫隐层）标志为$a^2_0…a^2_n$，并称之为“激活单元”。$a^{(j)}_i =$第j层i个激活单元$Θ^{(j)}$控制从j层映射到j+1层的权重矩阵 如果我们有一个隐层，则模型看起来如下： $\\begin{bmatrix}x_0 \\\\ x_1\\\\ x_2\\\\ x_3\\end{bmatrix}→\\begin{bmatrix}a^{(2)}_1\\\\a^{(2)}_2\\\\a^{(2)}_3\\end{bmatrix}→h_Θ(x)$ 每一个“激活”节点是这样得到的：$a^{(2)}_1=g(Θ^{(1)}_{10}x_0+Θ^{(1)}_{11}x_1+Θ^{(1)}_{12}x_2+Θ^{(1)}_{13}x_3)$$a^{(2)}_2=g(Θ^{(1)}_{20}x_0+Θ^{(1)}_{21}x_1+Θ^{(1)}_{22}x_2+Θ^{(1)}_{23}x_3)$$a^{(2)}_3=g(Θ^{(1)}_{30}x_0+Θ^{(1)}_{31}x_1+Θ^{(1)}_{32}x_2+Θ^{(1)}_{33}x_3)$$h_Θ(x)=a^{(3)}_1=g(Θ^{(2)}_{10}a^{(2)}_0+Θ^{(2)}_{11}a^{(2)}_1+Θ^{(2)}_{12}a^{(2)}_2+Θ^{(2)}_{13}a^{(2)}_3)$ 也就是说，要计算这个模型的激活节点，我们需要一个3*4的参数矩阵。我们将每行参数应用于我们的输入以获取一个激活节点的值。我们的假设函数输出是将逻辑函数应用于激活节点和参数$Θ^{(2)}$的乘积之和,其中$Θ^{(2)}$包含了第二层节点的权重。 每一层都有一个自己的参数（权重）矩阵。该权重矩阵的大小取决于：如果该网络的$j$层有$s_j$个单元，$j+1$层有$s_{j+1}$个单元，那么权重矩阵$Θ_j$的大小将为$s_{j+1}×(s_j+1)$。其中，+1是“偏向节点”$x_0$和$Θ^{(j)}_0$项的运算。换句话说，输出节点中没有偏向节点，但输入节点中则包含偏向节点。 举个例子：层1有2个输入节点，而层2有4个激活节点，那么参数矩阵$Θ^{(j)}$则是一个4*3的矩阵，其中，$s_j=2$，$s_{j+1}=4$，则$s_{j+1}×(s_j+1)=4*3$ 模型表示 II在这一节当中，我们将对上述的函数实现向量化。我们将要定义一个新的变量$z^{(j)}_k$来包含g函数中的参数。在前面的例子中，我们可用z来替代所有的参数：$a^{(2)}_1=g(z^{(2)}_1)$$a^{(2)}_2=g(z^{(2)}_2)$$a^{(2)}_3=g(z^{(2)}_3)$ 换句话说，对于层j=2，第k个节点，变量z如下:$z^{(2)}_k=Θ^{(1)}_{k0}x_0+Θ^{(1)}_{k1}x_1+Θ^{(1)}_{kn}x_n$ 向量化的$x$和$z^j$如下：$x=\\begin{bmatrix}x_0\\\\x_1\\\\…\\\\x_n\\end{bmatrix} ,z^{(j)}=\\begin{bmatrix}z^{(j)}_1\\\\z^{(j)}_2\\\\…\\\\z^{(j)}_n\\end{bmatrix}$ 将$x$表示为$a^{(1)}$，我们可以重新整理公式如下：$z^{j}=Θ^{(j-1)}a^{(j-1)}$可以看出，$Θ^{(j-1)}$的大小为$s_j×(n+1)$，其中$s_j$是激活节点的数目,$a^{(j-1)}$是$n+1$维的向量，显然$z^{j}$的大小将为$s_j$。 现在，我们可以得到j层的激活节点：$a^{(j)}=g(z^{(j)})$，其中函数g将会逐元素的应用在向量$z^{(j)}$上。在我们计算完$a^{(j)}$后，我们可以加一个偏向单元（等于1），也就是$a_0^{(j)}$。为了计算我们最终的假设函数，我们首先要计算另一个z向量：$z^{j+1}=Θ^{(j)}a^{(j)}$然后我们得到最后的结果如下：$h_Θ(x)=a^{(j+1)}=g(z^{(j+1)})$ 可以看到在最后一步中，层j和层j+1之间做的是和逻辑回归同样的事情。 在神经网络中，这些中间层使得我们可以很优雅地生成更加有趣且复杂的非线性假设函数。 例子和直观理解 I一个简单的例子是把神经网络应用到预测$x_1$和$x_2$的逻辑与(只有当$x_1$和$x_2$同时为1的时候返回True)。 我们的函数如下：$\\begin{bmatrix}x_0\\\\x_1\\\\x_2\\end{bmatrix}→\\begin{bmatrix}g(z^{(2)})\\end{bmatrix}→hΘ(x)$,其中偏向项$x_0=1$。 设置第一个$Θ$矩阵如下：$Θ^{(1)}=\\begin{bmatrix}-30\\\\20\\\\20\\end{bmatrix}$ 这将会导致假设函数的输出仅在$x_1$和$x_2$同时为1的时候为1。 换句话说：$h_Θ(x)=g(−30+20x_1+20x_2)$$x_1=0$ 且 $x_2=0$ 那么 $g(−30)≈0$$x_1=0$ 且 $x_2=1$ 那么 $g(−10)≈0$$x_1=1$ 且 $x_2=0$ 那么 $g(−10)≈0$$x_1=1$ 且 $x_2=1$ 那么 $g(10)≈1$ 也就是说我们可以通过使用小型神经网络,而不是使用实际的与门来构建计算机中的基本操作之一。当然，神经网络也可以用来模拟所有其他的逻辑门。 例子和直观理解 II我们可以这样构建与（AND）、非(NOR)、或（OR）等逻辑门的参数矩阵$Θ^{(1)}$：AND:$Θ^{(1)}=\\begin{bmatrix}−30&amp;20&amp;20\\end{bmatrix}$NOR:$Θ^{(1)}=\\begin{bmatrix}10&amp;−20&amp;−20\\end{bmatrix}$OR:$Θ^{(1)}=\\begin{bmatrix}−10&amp;20&amp;20\\end{bmatrix}$ 通过这些，我们可以组合出同或（XNOR）逻辑门（当$x_1$和$x_2$同时为1或0时为1）。$\\begin{bmatrix}x_0\\\\x_1\\\\x_2\\end{bmatrix}→\\begin{bmatrix}a^{(2)}_1\\\\a^{(2)}_2\\end{bmatrix}→\\begin{bmatrix}a^{(3)}\\end{bmatrix}→hΘ(x)$ 对于第一层和第二层之间的过渡，我们将使用$Θ^{(1)}$,其中结合了AND和NOR的值：$Θ^{(1)}=\\begin{bmatrix}−30&amp;20&amp;20\\\\10&amp;−20&amp;−20\\end{bmatrix}$ 而第二层和第三层之间的过渡，我们将使用$Θ^{(2)}$（使用了OR的值）：$Θ^{(2)}=\\begin{bmatrix}−10&amp;20&amp;20\\end{bmatrix}$ 最后整理一下所有节点：$a^{(2)}=g(Θ^{(1)}⋅x)$$a^{(3)}=g(Θ^{(2)}⋅a^{(2)})$$h_Θ(x)=a^{(3)}$ 到这里为止，我们为XNOR操作构建了两个隐层。 多元分类在神经网络中，如果想要进行多元分类，需要使得假设函数返回一个向量组。 比如，我们想要将数据分为4类：$\\begin{bmatrix}x_0\\\\x_1\\\\x_2\\\\…\\\\x_n\\end{bmatrix}→\\begin{bmatrix}a^{(2)}_0\\\\a^{(2)}_1\\\\a^{(2)}_2\\\\…\\end{bmatrix}→\\begin{bmatrix}a^{(3)}_0\\\\a^{(3)}_1\\\\a^{(3)}_2\\\\…\\end{bmatrix}→\\begin{bmatrix}h_Θ(x)_1\\\\h_Θ(x)_2\\\\h_Θ(x)_3\\\\h_Θ(x)_4\\end{bmatrix}→$ 我们对一组输入的假设函数输出结果可能如下所示：$h_Θ(x)=\\begin{bmatrix}0\\\\0\\\\1\\\\0\\end{bmatrix}$这种情况意味着，我们的结果类是第三个类。我们可以将我们的结果类定义为y：$y^{(i)}=\\begin{bmatrix}1\\\\0\\\\0\\\\0\\end{bmatrix},\\begin{bmatrix}0\\\\1\\\\0\\\\0\\end{bmatrix},\\begin{bmatrix}0\\\\0\\\\1\\\\0\\end{bmatrix},\\begin{bmatrix}0\\\\0\\\\0\\\\1\\end{bmatrix}$假设函数对一组输入的最终输出值将是y中的一个元素。","categories":[{"name":"Coursera Ng 笔记","slug":"Coursera-Ng-笔记","permalink":"http://yoursite.com/categories/Coursera-Ng-笔记/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/tags/机器学习/"}]},{"title":"正则化","slug":"正则化","date":"2018-06-11T05:33:42.000Z","updated":"2018-08-14T08:38:07.000Z","comments":true,"path":"2018/06/11/11/","link":"","permalink":"http://yoursite.com/2018/06/11/11/","excerpt":"正则化旨在解决过拟合问题。","text":"正则化旨在解决过拟合问题。 高偏差或者说欠拟合是指假设函数映射与数据的趋势相差很大。这种现象可能会发生在当假设函数过于简单或者使用过少的特征数的情况。比如说，我们的假设函数为$ h_\\theta(x) = \\theta_0 + \\theta_1x_1 + \\theta_2x_2$，我们希望这个线性模型将很好地拟合训练数据，且泛化能力较好（泛化能力：是指机器学习算法对新样本的适应能力。泛化能力好的算法能较好地预测新数据），但情况却并非如此。 而另一种极端情况，过拟合或高方差是指一个假设函数能很好的拟合数据，但不能很好地预测新数据。这种现象通常是由一个复杂的函数造成的，它会产生大量与数据无关的不必要的曲线和角度。 过拟合在线性和逻辑回归种都可能出现。解决过度拟合问题有两个主要方法： 减少功能的数量a）手动选择要保留的功能。b）使用模型选择算法（后面将会提到）。 正则化保留所有功能，但减小参数$\\theta_j$。当我们有很多稍微有用的功能时，正则化是一个不错的方法。 成本函数如果我们的假设函数过度拟合，那么我们可以通过增加成本来减少函数中某些项的权重。比如说，我们希望下面这个函数更偏向二次函数：$θ_0+θ_1x+θ_2x^2+θ_3x^3+θ_4x^4$也就是说，我们想要减少$θ_3x^3$和$θ_4x^4$的影响。我们可以这样更改成本函数，而不是直接删除这两个特征。$min _θ \\frac{1}{2m}$$\\sum_{i=1}^{m}(h_θ(x^{(i)})-y^{(i)})^2+1000⋅θ_3^2+1000⋅θ_4^2$ 可以看到，我们加了两个额外的项在最后面来增大这两个项的成本。而在成本函数中，我们想要最小化结果，使其靠近0，就不得不使得$\\theta_3$和$\\theta_4$接近0。这将大大降低了假设函数中的$θ_3x^3$和$θ_4x^4$ 我们也可以用一个总和来调整我们所有的θ参数：$min _θ \\frac{1}{2m}$$[\\sum_{i=1}^{m}(h_θ(x^{(i)})-y^{(i)})^2+λ\\sum_{j=1}^n \\theta^2_j]$ 其中λ是正则化参数。它决定了我们theta参数的成本增加的幅度。可以在交互式绘图中看看正则化的效果：https://www.desmos.com/calculator/1hexc8ntqp 使用上述成本函数和额外的正则项，我们可以使假设函数的输出更为平滑以减少过度拟合。但如果选择的λ太大，可能会过多地消除该特征而导致欠拟合现象。 正则化线性回归上面我们提到可以将正则化应用于线性回归和逻辑回归。这里，我们先感受一下正则化线性回归。 梯度下降修改梯度下降函数，把$\\theta_0$和其余的参数分离，因为我们不想惩罚$\\theta_0$项。(正则项也被成为惩罚项，对某个参数正则化，也被称为惩罚某个参数。)重复{ $\\theta_0:=\\theta_0 - \\alpha \\frac{1}{m} \\sum_{i=1}^m(h_\\theta(x^{(i)})-h^{(i)})x^{(i)}_0$ $\\theta_j:=\\theta_0 - \\alpha [\\frac{1}{m} \\sum_{i=1}^m(h_\\theta(x^{(i)})-h^{(i)})x^{(i)}_j+\\frac{\\lambda}{m}\\theta_j] , j∈{1,2…n}$} 显然，$\\frac{\\lambda}{m}\\theta_j$的作用就是正则化。稍微调整一下,上面的更新规则也可以这样表示： $\\theta_j:=θ_j(1-α\\frac{λ}{m})-\\theta_0 - \\alpha \\frac{1}{m} \\sum_{i=1}^m(h_\\theta(x^{(i)})-h^{(i)})x^{(i)}_j$ 显然，这个式子中第一项$1-α\\frac{λ}{m}$总是小于1。直观上，你可以看得出每一次迭代都会按照一定程度减小$\\theta_j$。而第二项，显然和原始的梯度下降是一样的。 正规方程现在我们把正则化应用到非迭代化的正规方程方法中。增加正则化后，方程与我们的原始方程基本一直，除了我们在括号内添加了另一个项：$θ=(X^TX+λ⋅L)^{-1}X^Ty$其中 $L =\\begin{bmatrix}0 &amp; 0 &amp; \\cdots\\ &amp;0\\\\0 &amp; 1 &amp; \\cdots\\ &amp; 0\\\\\\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\0 &amp; 0 &amp; \\cdots\\ &amp; 1\\end{bmatrix}$ L是一个左上角为0，对角线下方为1，其他位为0的矩阵。其大小为$(n + 1)×(n + 1)$。直观可以看做一个单位阵（不包括$x_0$）乘以数λ。 如我们所知，如果$m≤n$，那么$X ^ TX$是不可逆的。但当我们添加$λ⋅L$项之后，$X^TX+λ⋅L$则变成了可逆的。 正则化逻辑回归逻辑回归的正则化实则和正则化线性回归类似。让我们从成本函数开始。 成本函数回顾逻辑回归的成本函数：$J(θ)=-\\frac{1}{m}\\sum_{i=1}^m[y^{(i)}log(h_θ(x^{(i)}))+(1-y^{(i)})log(1-h_θ(x^{(i)}))]$同样的，我们把正则项加在成本函数的后面：$J(θ)=-\\frac{1}{m}\\sum_{i=1}^m[y^{(i)}log(h_θ(x^{(i)}))+(1-y^{(i)})log(1-h_θ(x^{(i)}))]+\\frac{\\lambda}{2m}\\sum_{j=1}^n\\theta^2_j$ 注意：正则项中$\\sum_{j=1}^n\\theta^2_j$明确排除偏向项$\\theta_0$。（θ向量共n+1个值，下标从0到n，从$\\theta_0$到$\\theta_n$），只从$\\theta_1$运行到$\\theta_n$。 梯度下降梯度下降的正则化也是和线性回归当中差不多的，我们将会把$\\theta_0$和其他的参数分开来更新，因为我们不想正则化$\\theta_0$项。重复直到收敛: { $θ_0 := θ_0 $ -$ α\\frac{1}{m}\\sum_{i=1}^m((h_θ(x^{(i)}) - y^{i})x^{(i)}_0)$ $θ_j := θ_j $ -$ α[\\frac{1}{m}\\sum_{i=1}^m((h_θ(x^{(i)}) - y^{i})x^{(i)}_j)+\\frac{\\lambda}{m}\\theta_j] $, $j∈{1,2…n}$}显然，使用了正则化，其与用于线性回归的梯度下降函数在形式上仍是相同的。 初始化单位特征向量常量特征事实证明，在开始进行任何培训之前，为特征池添加一个不变的特征至关重要。通常情况下，这个特征对于每个训练集都是1。具体来说，如果X是你的特征矩阵，那么$X_0$是一个单位向量。 下面解释需要常量特征的原因。这个常量特征也被称为“偏差”项，可以调整特征以更好地适应数据。 比如我们只考虑一个特征$X_1$，没有$X_0$的公式是$\\theta_1 * X_1 = y$。显然，这是一条始终穿过原点的线，斜率为$\\frac{y}{\\theta_1}$。而添加了$X_0$项则使得这条线通过y轴上的不同点成为可能。换句话说，有偏差项能更好地调整数据，毕竟并非所有最拟合数据的模型都通过原点$(0,0)$。","categories":[{"name":"Coursera Ng 笔记","slug":"Coursera-Ng-笔记","permalink":"http://yoursite.com/categories/Coursera-Ng-笔记/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/tags/机器学习/"}]},{"title":"逻辑回归","slug":"逻辑回归","date":"2018-06-07T06:00:09.000Z","updated":"2018-08-14T08:38:41.000Z","comments":true,"path":"2018/06/07/10/","link":"","permalink":"http://yoursite.com/2018/06/07/10/","excerpt":"现在，我们从回归问题转换到了分类问题。不要被“逻辑回归”这个名字所迷惑，取这个名字是由于一些历史的原因，实则并不是一个回归问题，而是一个分类问题。","text":"现在，我们从回归问题转换到了分类问题。不要被“逻辑回归”这个名字所迷惑，取这个名字是由于一些历史的原因，实则并不是一个回归问题，而是一个分类问题。以往我们的输出y的值常常是一个连续的范围，而在二元分类中，取而代之的是0和1，即y∈{0,1}。其中，0通常表示“否定类”，1表示“肯定类”，但你可以自由地给它分配任何表示。 由于我们现在只做两个类，所以也被称为“二元分类问题”。解决这个问题，一种方法是使用线性回归，并将所有大于0.5的预测值映射为1，将小于0.5的所有预测值映射为0。显然此方法效果不佳，因为分类实际上不是线性函数。 假设函数我们的假设函数需要满足:$0≤h_θ(x)≤1$ 新的假设函数使用“Sigmoid函数”，也称为“Logistic逻辑函数”： $h_θ(x)=g(θ^Tx)$$z=θ^Tx$$g(z)=\\frac{1}{1+e-z}$ 这里显示的函数g（z）将任何实数映射到（0,1）区间，使得它可用于将任意值函数转换为更适合分类的函数。你可以线上感受一下：sigmoid函数在线交互式绘图。 可以这样理解：你想将范围限制在0和1之间，可以从旧的假设函数$\\theta^Tx$（线性回归）开始， 然后将其代入Logistic函数。$h_\\theta$将会给出输出是1的概率。比如$h_\\theta=0.7$，那么我们的输出为1的概率为70%。$h_θ(x)=P(y=1|x;θ)=1-P(y=0|x;θ)$$P(y=0|x;θ)+P(y=1|x;θ)=1$ 显然，输出为0的概率则等于1-输出为1的概率（比如，如果1的概率为0.7，那么输出为0的概率则为0.3）。 决策边界为了得到离散的0或1分类，我们可以如下转换假设函数的输出：$h_θ(x)≥0.5→y=1$$h_θ(x)&lt;0.5→y=0$ 当你的输入≥0时，logistic函数输出将会≥0.5。即$g(z)≥0.5$当$z≥0$ 总结一下:$z=0,e0=1⇒g(z)=1/2$$z→∞,e^{-∞}→0⇒g(z)=1$$z→-∞,e^∞→∞⇒g(z)=0$ 所以说，当我们的输入为$\\theta ^TX$,那么意味着：$h_θ(x)=g(θ^Tx)≥0.5$当$θ^Tx≥0$ 换言之：$θ^Tx≥0⇒y=1$$θ^Tx&lt;0⇒y=0$ 而决策边界指的时一条线，这条线可以将y=0和y=1划分为两个区域。这条线由我们的假设函数产生。（与线性回归不同，线性回归中假设函数试图构造一条线将数据连接起来） 举个例子： $θ=\\begin{bmatrix}5\\\\-1\\\\0\\end{bmatrix}$$y=1$若$ 5+(-1)x_1+0x_2≥0$$5-x_1≥0$$-x_1≥-5$$x_1≤5$ 在这个例子中，我们的决策边界是$x_1=5$这条线,线的左边y=1,线的右边y=0。 需要重申的是，sigmoid函数的输入并不一定要是线性的（比如：$\\theta ^T X$）,也可以是一个圆（比如：$z=θ_0+θ_1x^2_1+θ_2x^2_2$）,或者是任意的形状。 成本函数我们不能再使用之前线性回归的成本函数,因为Logistic函数会使得输出呈波浪形，导致许多局部最优。换句话说，它不是一个凸函数。 新的成本函数如下： $J(θ)=\\frac{1}{m}\\sum_{i=1}^mCost(h_θ(x^(i)),y^(i))$$Cost(h_θ(x),y)=-log(h_θ(x)) $若$ y = 1$$Cost(h_θ(x),y)=-log(1-h_θ(x))$若$ y = 0$ 可以看出，y与假设函数的预测值越远，成本函数输出就越大。如果y等于预测值，那么成本函数输出则为0：$Cost(h_θ(x),y)=0 $若$ h_θ(x)=y$$Cost(h_θ(x),y)→∞ $若$ y=0 $且$ h_θ(x)→1$$Cost(h_θ(x),y)→∞ $若$ y=1 $且$ h_θ(x)→0$ 可以这样通俗的理解： 如果我们的正确答案’y’为0，那么如果我们的假设函数也输出0，则成本函数输出将为0.如果我们的假设接近1，则成本函数将接近无穷大。 如果我们的正确答案’y’是1，那么如果我们的假设函数输出1，则成本函数输出将为0.如果我们的假设接近0，则成本函数将接近无穷大。 用这种方式编写成本函数可以保证J（θ）对于逻辑回归是凸函数（只有一个最优值）。 简化成本函数和梯度下降我们可以把成本函数的两种情况简化成一种：$Cost(h_θ(x),y)=-ylog(h_θ(x))-(1-y)log(1-h_θ(x))$把整个成本函数写全：$J(θ)=-\\frac{1}{m}\\sum_{i=1}^m[y^{(i)}log(h_θ(x^{(i)}))+(1-y^{(i)})log(1-h_θ(x^{(i)}))]$ 向量形式：$h = g(X\\theta)$$J(\\theta) = \\frac{1}{m}⋅(-y^Tlog(h)-(1-y)^Tlog(1-h))$ 梯度下降梯度下降的总体形式可以这样概括:重复{ $θ_j := θ_j - α\\frac{∂}{∂θ_j} J(θ)$}通过计算，我们可以得到其梯度下降形式和线性回归中梯度下降的形式时一样的(同样的，我们也必须同时地更新所有的参数)：重复直到收敛: { $θ_j := θ_j $ -$ α\\frac{1}{m}\\sum_{i=1}^m((h_θ(x^{(i)}) - y^{i})x^{(i)}_j)$}类似于线性回归$∇J(θ)$的向量化版本如下：$∇J(θ)= \\frac{1}{m}⋅X^T⋅(g(X⋅θ)−\\vec y)$ 高级优化“共轭梯度下降”，“BFGS”和“L-BFGS”这些方法都比较复杂，可以用来代替梯度下降来更快速地优化参数$\\theta$。这些方法都有现成的库可以用，无需自己实现。 多元分类：one-vs-all多元分类指的是将数据分为两类以上。我们将扩展输出类别的定义，使得y = {0,1 … n}，而不是y = {0,1}。 在这种情况下，我们将问题划分为n+1个（+1，因为索引从0开始）二元分类问题;在每一个二元分类问题中，我们都预测’y’是我们其中一个类的概率。$y∈{0,1…n}$$h^{(0)}_θ(x)=P(y=0|x;θ)$ $h^{(1)}_θ=P(y=1|x;θ)$ $⋯$$h^{(n)}_θ=P(y=n|x;θ)$$prediction=max_i(h^{(i)}_θ(x))$ 主要方法：首先选择一个类别，然后把所有其他类都集中到另一个类别中。反复这样做，对每个二元分类问题​​应用二元逻辑回归，然后使用返回最高值作为我们的预测。","categories":[{"name":"Coursera Ng 笔记","slug":"Coursera-Ng-笔记","permalink":"http://yoursite.com/categories/Coursera-Ng-笔记/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/tags/机器学习/"}]},{"title":"正规方程","slug":"正规方程","date":"2018-06-07T02:53:41.000Z","updated":"2018-08-14T08:38:12.000Z","comments":true,"path":"2018/06/07/9/","link":"","permalink":"http://yoursite.com/2018/06/07/9/","excerpt":"正规方程是一种不需要迭代就能找到最优参数$\\theta$的方法。公式：$θ=(X^TX)^{−1}X^Ty$正规方程不需要特征缩放。","text":"正规方程是一种不需要迭代就能找到最优参数$\\theta$的方法。公式：$θ=(X^TX)^{−1}X^Ty$正规方程不需要特征缩放。 如果有兴趣的话，可以在以下链接查看证明过程。https://en.wikipedia.org/wiki/Linear_least_squares_(mathematics)http://eli.thegreenplace.net/2014/derivation-of-the-normal-equation-for-linear-regression 下面是一个梯度下降和正规方程的对比表格： 梯度下降 正规方程 需要选择学习率$\\alpha$ 不需要选择学习率$\\alpha$ 需要多次迭代 不需要多次迭代 复杂度$o(kn^2)$ 复杂度$o(n^3)$,需要计算$X^TX$的逆 当n比较大的时候，较为适用 当n比较大的时候，运算缓慢 如果使用正规方程式，计算逆的复杂度为$o(n^3)$。所以，如果我们有非常大量的特征，使用正规方程则会非常的缓慢。实践证明，当n大于10000时，用迭代的方式（梯度下降）来替代正规方程将会更加合适。 正规方程的不可逆性在正规方程中，我们需要计算$X^TX$的逆，而$X^TX$在一些情况是不可逆的，造成这个现象的情况有： 冗余的特征：两个特征之间是紧密联系的。（比如他们是线性相关的） 特征太多：在这种情况，可以删除掉一些特征或者使用“正则化”（之后会讲解）。 总结解决不可逆情况的方法主要包括： 删除和其他功能线性相关的功能。 在功能过多时删除一个或多个功能。 Tips:在基本线性代数复习中，提到了有一些矩阵存在逆矩阵，而有一些矩阵则不存在逆矩阵。在matlab中，若矩阵A存在逆矩阵，则可以用inv(A)来求其逆，否则可以使用pinv(A)求其伪逆。","categories":[{"name":"Coursera Ng 笔记","slug":"Coursera-Ng-笔记","permalink":"http://yoursite.com/categories/Coursera-Ng-笔记/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/tags/机器学习/"}]},{"title":"特征和多项式回归","slug":"特征和多项式回归","date":"2018-06-06T09:34:47.000Z","updated":"2018-08-14T08:38:16.000Z","comments":true,"path":"2018/06/06/8/","link":"","permalink":"http://yoursite.com/2018/06/06/8/","excerpt":"我们可以通过几种不同的方式来改进我们的特征和假设函数的形式。比如将多个功能合并为一个特征：我们可以将$x_1$和$x_2$组合成$x_1⋅x_2$，以此变成一个新的特征$x_3$。","text":"我们可以通过几种不同的方式来改进我们的特征和假设函数的形式。比如将多个功能合并为一个特征：我们可以将$x_1$和$x_2$组合成$x_1⋅x_2$，以此变成一个新的特征$x_3$。 多项式回归如果直线并不能很好的拟合数据，那么我们可能需要的不是线性回归（直线形式）。此时，我们可以通过使其成为二次函数，立方函数或平方根函数（或任何其他形式）来改变我们的假设函数的行为或曲线。举个例子：如果我们的假设函数是$h\\theta(x)=\\theta_0+\\theta_1x_1$，那么我们可以基于$x_1$增加额外的特征。比如： 二项式函数：$h_\\theta(x)=\\theta_0+\\theta_1x_1+\\theta_2x_1^2$ 立方函数：$h_\\theta(x)=\\theta_0+\\theta_1x_1+\\theta_2x_1^2+\\theta_3x_1^3$ 平方根函数：$h_\\theta(x)=\\theta_0+\\theta_1x_1+\\theta_2\\sqrt {x_1}$ 其中，在立方形式当中，我们新建两个特征$x2$和$x3$，其中$x2=x_1^2$，$x3=x_1^3$,其他形式也是类似的，我们使用新特征来表示改变后的特征。 一个重点：如果你选择了这些多项式函数，那么特征的缩放则显得尤为重要。比如，如果$x_1$在1-1000的范围，那么$x_1^2$的范围就变成了1-1000000，$x_1^3$的范围就变成了1-1000000000。","categories":[{"name":"Coursera Ng 笔记","slug":"Coursera-Ng-笔记","permalink":"http://yoursite.com/categories/Coursera-Ng-笔记/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/tags/机器学习/"}]},{"title":"梯度下降技巧","slug":"梯度下降技巧","date":"2018-06-04T03:19:06.000Z","updated":"2018-08-14T08:38:03.000Z","comments":true,"path":"2018/06/04/7/","link":"","permalink":"http://yoursite.com/2018/06/04/7/","excerpt":"","text":"调试梯度下降:在x轴上绘制迭代次数，然后将成本函数J（θ）绘制在梯度下降的迭代次数上。如果J（θ）增加，那么你可能需要减少α。 自动收敛测试:如果J（θ）在一次迭代中减小小于E，则说明已经收敛，其中E是一些小值，例如$10^-3$。但是在实践中很难选择这个阈值。实践证明，如果学习率α足够小，那么J（θ）将在每次迭代中减少。Andrew Ng建议在调整α的过程中，减少的幅度为3的倍数。","categories":[{"name":"Coursera Ng 笔记","slug":"Coursera-Ng-笔记","permalink":"http://yoursite.com/categories/Coursera-Ng-笔记/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/tags/机器学习/"}]},{"title":"特征归一化","slug":"特征归一化","date":"2018-06-02T07:50:03.000Z","updated":"2018-08-14T08:38:22.000Z","comments":true,"path":"2018/06/02/6/","link":"","permalink":"http://yoursite.com/2018/06/02/6/","excerpt":"我们可以通过让每个输入值在大致相同的范围内，以此来加速梯度下降。这是因为θ在小范围内能迅速下降，相反在大范围内则下降缓慢.因此当变量非常不均匀时，θ下降到最优值会十分低效。","text":"我们可以通过让每个输入值在大致相同的范围内，以此来加速梯度下降。这是因为θ在小范围内能迅速下降，相反在大范围内则下降缓慢.因此当变量非常不均匀时，θ下降到最优值会十分低效。 为了防止这种低效的情况，我们需要修改输入变量的范围，使它们大致相同。理想情况下：$−1 ≤ x_{(i)} ≤ 1$或者$−0.5 ≤ x_{(i)} ≤ 0.5$ 当然这些不是确切的要求,我们只是想加快速度，使得所有输入变量大致在这些范围中的一个范围内。 有两种技术可以帮助我们进行特征归一化： 特征缩放:其中一种方法是将输入值除以输入变量的范围（即最大值减去最小值），导致新的范围仅为1。 平均归一化:其中一种方法是从输入变量的值中减去输入变量的平均值,使得输入变量的新平均值为零。 要实现这两种技术，需要按照以下公式所示调整输入值： $x_i:=\\frac{x_i - μ_i}{s_i}$ 其中$μ_i$是输入变量的平均值，$s_i$是输入变量的范围（即最大值减去最小值）,$s_i$也可以是输入变量的标准偏差。（注意，除以范围和除以标准偏差得出的结果有所不同。） 举个例子：$x_i$是房子的价格（在100-2000的范围内），平均价格为1000，那么，经过调整之后，$x_i=\\frac {price-1000}{1900}$","categories":[{"name":"Coursera Ng 笔记","slug":"Coursera-Ng-笔记","permalink":"http://yoursite.com/categories/Coursera-Ng-笔记/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/tags/机器学习/"}]},{"title":"多变量线性回归","slug":"多变量线性回归","date":"2018-06-01T14:07:14.000Z","updated":"2018-08-14T08:37:36.000Z","comments":true,"path":"2018/06/01/6/","link":"","permalink":"http://yoursite.com/2018/06/01/6/","excerpt":"具有多个变量的线性回归也称为“多元线性回归”，其可以有任意数量的输入变量。","text":"具有多个变量的线性回归也称为“多元线性回归”，其可以有任意数量的输入变量。 符号标记： $x^{(i)}_j$ = 第i个训练样例中特征j的值 $x^{(i)}$ = 第i个训练样例的所有特征输入的列向量 $m$ = 训练样例的数量 $n$ = $\\begin{vmatrix}x^{(i)}\\end{vmatrix}$（特征的数量） 假设函数现在按如下定义假设函数的多变量形式，以适应这些多重特征：$h_\\theta(x) = \\theta_0+\\theta_1x_1+\\theta_2x_2+\\theta_3x_3+…++\\theta_nx_n$ 为了更为直观地介绍这个函数，我们可以把$\\theta_0$看做是房子的底价，\\theta_1看做是每平方米的价格，$\\theta_2$看做是每层的价格等等，则$x_1$是房子的占地面积，$x_2$是房子的楼层数。 使用矩阵乘法的定义，我们的多变量假设函数可以简洁地表示为：$h_\\theta(x) = \\begin{bmatrix}\\theta_0 &amp; \\theta_1 &amp;…&amp; \\theta_n\\end{bmatrix}\\begin{bmatrix}x_0 \\\\ x_1 \\\\…\\\\ x_n\\end{bmatrix} = \\theta^T x$ 上面是一个样例的假设函数的向量化形式。 注意：为了方便起见，假设$x^{(i)}_0 = 1(i∈1,…,m)$ 则训练数据则被逐行的存储在X当中，如：$X=\\begin{bmatrix} x^{(1)}_0 &amp;x^{(1)}_1\\\\x^{(2)}_0&amp;x^{(2)}_1\\\\x^{(3)}_0&amp;x^{(3)}_1 \\end{bmatrix},\\theta=\\begin{bmatrix}\\theta_0 \\\\ \\theta_1\\end{bmatrix}$ 你可以计算并得到假设函数将会是一个m×1的列向量：$h_\\theta(X)=X\\theta$ 接下来的笔记中，X将会像上面那样代表训练数据逐行地存储。 成本函数当参数向量$\\theta$（类型为$R^{n+1}$或者说是$R^{(n+1)*8}$）,成本函数如下：$J(\\theta) = \\frac{1}{2m}\\sum_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})^2$ 向量化的形式如下：$J(\\theta)= \\frac{1}{2m}(X\\theta-\\vec y)^T(X\\theta-\\vec y)$,其中$\\vec y$涵盖了所有的y值。 多变量的梯度下降梯度下降的公式的形式基本上是相同的，我们需要做的是根据n个特征来重复这些公式：重复直到收敛: { $θ_0 := θ_0 $ -$ α\\frac{1}{m}\\sum_{i=1}^m(h_θ(x^{(i)}) - y^{(i)})x^{(i)}_0$ $θ_1 := θ_1 $ -$ α\\frac{1}{m}\\sum_{i=1}^m(h_θ(x^{(i)}) - y^{(i)})x^{(i)}_1$ $θ_2 := θ_2 $ -$ α\\frac{1}{m}\\sum_{i=1}^m(h_θ(x^{(i)}) - y^{(i)})x^{(i)}_2$ …} 换一种形式： 重复直到收敛: { $θ_j := θ_j $ -$ α\\frac{1}{m}\\sum_{i=1}^m(h_θ(x^{(i)} - y^{(i)})x^{(i)}_j)$} 矩阵符号梯度下降规则可以这样表示： $\\theta := \\theta - \\alpha∇J(θ)$其中$∇J(θ)$是一个列向量的形式：$∇J(θ)=\\begin{bmatrix}\\frac{∂J(θ)}{∂θ_0} \\\\\\frac{∂J(θ)}{∂θ_1}\\\\…\\\\\\frac{∂J(θ)}{∂θ_n}\\end{bmatrix}$ 梯度的第j个元素是两项的乘积之和：$\\frac{∂J(θ)}{∂θ_j} $= $\\frac{i}{m}\\sum_{i=1}^m(h_\\theta(x^{(i)})-y^{(i)})x^{(i)}_j $=$\\frac{i}{m}\\sum_{i=1}^mx^{(i)}_j(h_\\theta(x^{(i)})-y^{(i)})$ 有时候，这两项的乘积之和可以表示为两个向量的乘积。 这里，$x^{(i)}_j($,其中$i=1,…,m)$表示训练集$X$第j列的m个元素$\\vec x_j$。 另一个项$(h_\\theta(x^{(i)})-y^{(i)})$是预测值$h_\\theta(x^{(i)})$和真值$y^{(i)}$误差的导数向量。重新整理一下$\\frac{∂J(θ)}{∂θ_j} $如下：$\\frac{∂J(θ)}{∂θ_j}=\\frac{1}{m}\\vec x_j^T(X\\theta - \\vec y)$ 则：$∇J(θ)=\\frac{1}{m}X^T(X\\theta - \\vec y)$ 最后，向量化形式的梯度下降则可以表示为：$\\theta := \\theta - \\frac{\\alpha}{m}X^T(X\\theta - \\vec y)$","categories":[{"name":"Coursera Ng 笔记","slug":"Coursera-Ng-笔记","permalink":"http://yoursite.com/categories/Coursera-Ng-笔记/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/tags/机器学习/"}]},{"title":"基本线性代数复习","slug":"基本线性代数复习","date":"2018-06-01T05:22:58.000Z","updated":"2018-08-14T08:37:31.000Z","comments":true,"path":"2018/06/01/5/","link":"","permalink":"http://yoursite.com/2018/06/01/5/","excerpt":"这一篇总结一点简单的线性代数知识","text":"这一篇总结一点简单的线性代数知识 矩阵和向量矩阵是二维数组$\\begin{bmatrix} a&amp;b&amp;c\\\\ d&amp;e&amp;f\\\\ g&amp;h&amp;i\\\\ j&amp;k&amp;l \\end{bmatrix}$ 上面的矩阵有四行三列，所以是一个4*3的矩阵。而向量可以说是一个多行一列的矩阵：$\\begin{bmatrix}w\\\\x\\\\y\\\\z\\end{bmatrix}$ 总的来说，向量可以说是矩阵的一个子集，上面的向量是一个4*1的矩阵。 符号标记： $A_{ij}$ 指矩阵A的i行j列的元素 一个n行向量被称为n维的向量 $v_i$ 指向量的第i行 在matlab中，数组的下标是从1开始的，而大部分其他语言则是从0开始的 矩阵通常用大写字母表示，向量则通常使用小写字母表示 纯量或者叫标量，指的是只有一个值的对象，既不是向量也不是矩阵。 $R$指一个纯量集合 $R^n$指一个n维的向量 加法和标量乘法加法和减法都是逐元素的，所以你可以简单地加或者减每一个对应的元素(当加或者减两个矩阵时，两个矩阵的尺寸大小必须是相同的)：$\\begin{bmatrix}a&amp;b\\\\c&amp;d\\end{bmatrix}$+$\\begin{bmatrix}w&amp;x\\\\y&amp;z\\end{bmatrix}$=$\\begin{bmatrix}a+w&amp;b+x\\\\c+y&amp;d+z\\end{bmatrix}$ 在标量乘法中，我们简单地将每一个元素都乘以这个标量值：$\\begin{bmatrix}a&amp;b\\\\c&amp;d\\end{bmatrix}$ $ * x$ = $\\begin{bmatrix}a*x&amp;b*x\\\\c*x&amp;d*x\\end{bmatrix}$ 矩阵向量乘法我们把向量的列和矩阵的每一行逐元素的相乘并把结果相加得到：$\\begin{bmatrix}a&amp;b\\\\c&amp;d\\\\e&amp;f\\end{bmatrix}$ $*$ $\\begin{bmatrix}x\\\\y\\end{bmatrix}$ = $\\begin{bmatrix}a*x+b*y\\\\c*x+d*y\\\\e*x+f*y\\end{bmatrix}$ 结果是一个向量，向量必须是这个乘法的第二项。且矩阵的列数必须等于向量的行数。比如： 一个m*n的矩阵乘以一个n*1的向量，结果则为m*1向量。 矩阵乘法我们将矩阵相乘分成若干个矩阵向量乘法，然后将结果串联起来：$\\begin{bmatrix}a&amp;b\\\\c&amp;d\\\\e&amp;f\\end{bmatrix}$ $*$ $\\begin{bmatrix}w&amp;x\\\\y&amp;z\\end{bmatrix}$ = $\\begin{bmatrix}a*w+b*y &amp; a*x+b*z\\\\c*w+d*y&amp;c*x+d*z\\\\e*w+f*y&amp;e*x+f*z\\end{bmatrix}$ 一个m*n的矩阵乘以一个n*o的矩阵，结果将会是一个m*o的矩阵。在上面的例子当中，一个3*2的矩阵乘以一个2*2的矩阵，结果是一个3*2的矩阵若两个矩阵相乘，则第一个矩阵的列数要和第二个矩阵的行数相同。 ####矩阵乘法的属性 没有交换律：A∗B≠B∗A 结合律： (A∗B)∗C=A∗(B∗C) 单位矩阵表示对角线上都为1，其余为0的矩阵:$\\begin{bmatrix}1&amp;0&amp;0\\\\0&amp;1&amp;0\\\\0&amp;0&amp;1\\end{bmatrix}$ 当单位矩阵被同样大小的矩阵相乘时，结果还是原来的矩阵。感觉就像一个数乘以1还是原来那个数一样。 当矩阵乘以单位矩阵形如：（A * I）时，单位阵应该与另一个矩阵的列匹配。当单位矩阵乘以矩阵形如：（I * A）时，单位阵应该与另一个矩阵的行匹配。 矩阵的逆和转置矩阵$A$的逆可以被表示为$A^{-1}$,矩阵和它的逆矩阵相乘为单位阵。如果一个矩阵不是方阵则没有逆矩阵（有伪逆矩阵）。在matlab中，我们可以用inv(A)来求矩阵的逆。如果一个矩阵没有逆矩阵，则这个矩阵是奇异矩阵（行列式为0的方阵）或者退化矩阵。 矩阵的转置可以看做将矩阵按顺时针方向旋转90°然后左右翻转。在matlab中我们可以通过函数transpos(A)或者 A’来计算矩阵的转置： $A=\\begin{bmatrix}a &amp; b\\\\c &amp; d\\\\e &amp; f\\end{bmatrix}$ $A^T=\\begin{bmatrix}a &amp; c &amp; e\\\\b &amp; d &amp; f\\end{bmatrix}$ 换句话说，$A_{ij} = A^T_{ji}$ 。","categories":[{"name":"Coursera Ng 笔记","slug":"Coursera-Ng-笔记","permalink":"http://yoursite.com/categories/Coursera-Ng-笔记/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/tags/机器学习/"}]},{"title":"梯度下降","slug":"梯度下降","date":"2018-05-29T14:35:41.000Z","updated":"2018-08-14T08:37:51.000Z","comments":true,"path":"2018/05/29/4/","link":"","permalink":"http://yoursite.com/2018/05/29/4/","excerpt":"前面我们已经学习了假设函数以及成本函数（一种测量假设函数拟合训练集的好坏程度的方法）。现在我们需要估计假设函数中的参数，此时，我们常用到梯度下降方法。","text":"前面我们已经学习了假设函数以及成本函数（一种测量假设函数拟合训练集的好坏程度的方法）。现在我们需要估计假设函数中的参数，此时，我们常用到梯度下降方法。 归根结底我们是基于$\\theta_0$和$\\theta_1$来描绘我们的假设函数$h_θ(x)$的。 而成本函数$J(θ_0,θ_1)$则被绘制为参数所预估的函数。 对于成本函数，我们可以这样描述： 成本函数不是绘制x和y本身，而是绘制假设函数的参数范围和选择特定参数集合的成本结果。 在成本函数当中，我们把$\\theta_0$ 放在x轴上，把$\\theta_1$放在y轴上，然后把成本函数放在z轴上。 在被绘制的图上的点则表示使用选择这些$\\theta$参数的成本函数的情况。 当我们的成本函数处于图的曲线的底部时，即当其值最小时，则说明我们已经成功找到了最优的参数。 那么，如何得到这个最优的参数集合呢？ 我们的方式是通过获取成本函数的导数（函数的切线）。切线的斜率是该点的导数，它会给我们一个走向的方向。 我们在下降得最陡的方向上降低成本函数，而每个下降的步长大小由参数α确定，也被称为学习率。 这里则涉及到了梯度下降算法如下：重复直到收敛：$θ_j := θ_j - α\\frac{∂}{∂θ_j} J(θ_0,θ_1)$其中，j=0,1 表示特征索引号你可以这样理解：重复直到收敛：$θ_j := θ_j$ - α[j维上的斜率或者说导数] 线性回归中的梯度下降当专门应用于线性回归的情况时，可以推导出一种新的梯度下降方程式。我们可以用我们的实际成本函数和我们的实际的假设函数来代替，并修改公式 ： 重复直到收敛: { $θ_0 := θ_0 $ -$ α\\frac{1}{m}\\sum_{i=1}^m(h_θ(x_i) - y_i)$ $θ_0 := θ_0 $ -$ α\\frac{1}{m}\\sum_{i=1}^m((h_θ(x_i) - y_i)x_i)$} 其中m是训练集的大小，$θ_0$是一个常数，且会和$θ_1$同时改变，而$x_i$和$y_i$是我们的训练集。 可以看到，我们把$θ_j$分成了$θ_0$和$θ_1$两个公式，且由于求导在$θ_1$的最后乘以了$x_i$ 所有这一切的关键在于，如果我们从猜测一些假设函数的初始化参数开始，然后重复应用这些梯度下降方程，我们的假设函数将变得越来越准确。","categories":[{"name":"Coursera Ng 笔记","slug":"Coursera-Ng-笔记","permalink":"http://yoursite.com/categories/Coursera-Ng-笔记/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/tags/机器学习/"}]},{"title":"单变量线性回归","slug":"单变量线性回归","date":"2018-05-27T07:05:59.000Z","updated":"2018-08-14T08:37:23.000Z","comments":true,"path":"2018/05/27/3/","link":"","permalink":"http://yoursite.com/2018/05/27/3/","excerpt":"模型表示 回顾线性回归问题，依据输入数据，我们把输入映射到一个连续的结果函数。 一个变量的线性回归也被称为“单变量线性回归”。 单变量线性回归被用于当你想要通过输入一个单变量x，并预测一个输出值y。(这里我们做的是监督学习，也就是说我们预先是知道输入/输出的效果的。)","text":"模型表示 回顾线性回归问题，依据输入数据，我们把输入映射到一个连续的结果函数。 一个变量的线性回归也被称为“单变量线性回归”。 单变量线性回归被用于当你想要通过输入一个单变量x，并预测一个输出值y。(这里我们做的是监督学习，也就是说我们预先是知道输入/输出的效果的。) 假设函数我们的假设函数具有一般形式：这就像一条直线的方程，我们给出θ0和θ1的值，就能得到估计的输出值。 ​换句话说，我们尝试创建一个函数hθ(x)，能将输入值x映射到输出值y上。 比如：假设我们有以下训练集： input x output y 0 4 1 7 2 7 3 8 现在我们随机的设置hθ(x) 中θ0=2，θ1=2，那么hθ(x)=2+2x.所以当输入为1时，通过假设函数，输出将会是4，这里误差为3。我们将尝试不同的θ0和θ1，试图通过映射在x-y平面上的数据点，找到最佳的拟合或者说最具代表性的”直线”。 成本函数有了假设函数，我们需要衡量它是否合适，此时成本函数则可以用来衡量假设函数的准确性。将假设函数由x得出的预测输出值和实际的y进行比较，并求平均值。此时，成本函数可以表示如下： 把上面的成本函数拆开，可以表示为X/2，其中X为hθ(xi)-yi 的平方的平均数，或者说是预测值与实际值的误差。 该函数也被称为“平方误差函数”或“均方误差”，其中平均值减半（函数前面乘了1/2），是为了方便后期求梯度下降。（乘以了1/2可以抵消求导时的平方项） 现在我们能够根据我们的正确结果测量预测函数的准确性，以便我们预测新的数据。 如果从视觉上来考虑这个问题，训练数据集就散布在x-y平面上。我们试图做出直线（hθ(x)），来通过这组散布的数据。我们的目标是获得最佳线路。尽可能合适的线将使得这些点到直线的平均垂直距离最小。在最好的情况下，这条线应该穿过训练数据集的所有点。在这种情况下，J（θ0，θ1）=0。","categories":[{"name":"Coursera Ng 笔记","slug":"Coursera-Ng-笔记","permalink":"http://yoursite.com/categories/Coursera-Ng-笔记/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/tags/机器学习/"}]},{"title":"无监督学习","slug":"无监督学习","date":"2018-05-24T03:05:34.000Z","updated":"2018-08-14T08:37:41.000Z","comments":true,"path":"2018/05/24/2/","link":"","permalink":"http://yoursite.com/2018/05/24/2/","excerpt":"无监督学习，换一句话说，我们不清楚输出的标签结果应该有什么，即使不知道变量的影响，我们也可以得到数据的结构","text":"无监督学习，换一句话说，我们不清楚输出的标签结果应该有什么，即使不知道变量的影响，我们也可以得到数据的结构 无监督学习的性质。 通常情况下，我们可以通过基于数据中变量之间的关系对数据进行聚类来推导出这种结构。 在无监督学习的情况下，没有基于预测结果的反馈，就像没有老师可以纠正你是否正确。 举个例子 聚类：以美国经济撰写的1000篇论文为例，依据不同的变量（如词频，句子长度，页数等），找到一种方法将这些论文自动分成若干组。 非聚类：“鸡尾酒party算法”可以找出混乱数据中的数据结构（比如从混乱的鸡尾酒派对音乐中识别个人的声音）(https://en.wikipedia.org/wiki/Cocktail_party_effect) .","categories":[{"name":"Coursera Ng 笔记","slug":"Coursera-Ng-笔记","permalink":"http://yoursite.com/categories/Coursera-Ng-笔记/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/tags/机器学习/"}]},{"title":"监督学习","slug":"监督学习","date":"2018-05-21T14:24:16.000Z","updated":"2018-08-14T08:38:25.000Z","comments":true,"path":"2018/05/21/1/","link":"","permalink":"http://yoursite.com/2018/05/21/1/","excerpt":"在机器学习算法当中，我们往往会有一个输入和输出，通常情况下，输入和输出存在一定的关系。而在监督学习中，我们会给出一个数据集（输入）并提供它的正确标签（输出）。","text":"在机器学习算法当中，我们往往会有一个输入和输出，通常情况下，输入和输出存在一定的关系。而在监督学习中，我们会给出一个数据集（输入）并提供它的正确标签（输出）。 监督学习的类别 回归问题在回归问题中，我们尝试预测出一个连续的输出结果。换句话说，我们将会将输入映射到一个连续的函数当中。 分类问题分类问题则相反，我们将尝试预测一个离散的结果。也就是说，我们将会尝试将输入数据映射到离散的类别中。 连续和离散 例子给出房地产市场的房子的大小（占地面积），试图预测它们的房价。房价是大小的一个输出连续函数，所以这是一个回归问题。我们可以把问题转换为分类问题：预测房子是否低于某个价格。这里，我们则依据价格将房子分类为两个离散的类别。 其他例子回归问题1、给出一个人的图片，我们需要根据给出的图片预测他/她的年龄。分类问题1、给出一个人的图片，预测他/她是高中生、大学生还是已经毕业的人。2、银行必须根据其信用记录决定是否向某人提供贷款。","categories":[{"name":"Coursera Ng 笔记","slug":"Coursera-Ng-笔记","permalink":"http://yoursite.com/categories/Coursera-Ng-笔记/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/tags/机器学习/"}]},{"title":"机器学习","slug":"机器学习","date":"2018-05-20T07:16:08.000Z","updated":"2018-08-14T08:37:46.000Z","comments":true,"path":"2018/05/20/0/","link":"","permalink":"http://yoursite.com/2018/05/20/0/","excerpt":"以往，人们不太正式地这样定义机器学习： 不通过明确地编程，而使得计算机拥有学习的能力的这样一个学习领域。","text":"以往，人们不太正式地这样定义机器学习： 不通过明确地编程，而使得计算机拥有学习的能力的这样一个学习领域。 Tom Mitchell 提供了这样一个新的定义 E(experience): 经验（在算法中相当于训练数据） T(task): 任务、目标（比如通过算法希望识别类型） P(probability): 预测的正确概率一个计算机程序从经验E中学习，并希望达到一个目标T，然后用P来衡量算法的性能（T的准确率），而对于经验E的学习将提升P 举个下棋的例子 E代表玩很多很多盘棋的经验 T代表下棋 P代表程序将赢得下一盘棋的概率 一般来说，任何机器学习的问题，都可以被分为两个大类 监督学习 无监督学习","categories":[{"name":"Coursera Ng 笔记","slug":"Coursera-Ng-笔记","permalink":"http://yoursite.com/categories/Coursera-Ng-笔记/"}],"tags":[{"name":"机器学习","slug":"机器学习","permalink":"http://yoursite.com/tags/机器学习/"}]}]}